{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Michaelis-Menten kinetics dynamics",
   "id": "606586832fe3295a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The Michaelis-Menten kinetics is given by the following system of (coupled) ordinary differential equations (ODEs):",
   "id": "fa73b03aeea0e5f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\dot{x}^{(\\nu)}_i = -x^{(\\nu)}_i + \\sum_j w_{i,j} \\cdot \\frac{x^{(\\nu)}_j}{1 + x^{(\\nu)}_j}, \\quad i, j \\in \\{1, \\dots, N\\}\n",
    "$$"
   ],
   "id": "2a54afd56cd70a3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TODOs\n",
    "- Use Pandas' DataFrame instead of messy python lists\n",
    "- \"Colonial expansion\" - Make the defects uneven (e.g. base_model W $->$ 10 Ws with p = 0.2 and 40 Ws with p = 0.8)\n",
    "- \"Colonial expansion\" should decrease GCL (higher p $->$ lower GCL)"
   ],
   "id": "93d7d29aa47e367d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T05:47:20.835179Z",
     "start_time": "2024-10-11T05:47:20.299745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Mathematical functions (ode solvers, spearman, PCA)\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "## TODO: Refactor to use pandas dataframes\n",
    "\n",
    "from gcl_library import jackknife"
   ],
   "id": "d4c1b3b541e35701",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\dot{x}^{(\\nu)}_i = -Bx^{(\\nu)}_i + \\sum_j w_{i,j} \\cdot \\frac{x^{(\\nu)}_j}{1 + x^{(\\nu)}_j}, \\quad i, j \\in \\{1, \\dots, N\\}\n",
    "$$"
   ],
   "id": "dca66a22852c4aa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T05:47:20.850594Z",
     "start_time": "2024-10-11T05:47:20.835179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up the system of ODEs\n",
    "def ode_system(t, x, W, B, zero_mask):\n",
    "    n = len(x)  # Get the number of elements in the state vector\n",
    "    derivative_vector = np.zeros(n)  # Initialize the derivative vector (set zeros as default)\n",
    "    for i in range(n):  # Loop over each element in the state vector\n",
    "        # Compute the sum term for the i-th element according to the formula given in the paper\n",
    "        sum_term = sum(W[i, j] * (x[j] / (1 + x[j])) for j in range(n) if j != i)\n",
    "        derivative_vector[i] = -B * x[i] + sum_term\n",
    "    # Set the derivative of the zeroed genes to 0\n",
    "    for z in zero_mask:\n",
    "        derivative_vector[z] = 0\n",
    "    return derivative_vector"
   ],
   "id": "1cf2934855a85579",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "N represents # of genes in each cell  \n",
    "num_of_cells (M) represents # of cells as well as # of defects matrices (defects of weight matrix w)\n",
    "p represents the probability of the base weight matrix to defect (non-zero elements probability to change)  \n",
    "A cohort is a group of cells with similar properties (in our case identical p value and the same base_model weight matrix)  \n",
    "A cell is a network of genes  \n",
    "A gene is a node in the network with its connection's represented by the relevant weight matrix W  \n",
    "We have <num_of_cohorts> cohorts, in each cohort we have <num_of_cells> (previously called M) cells, all cells in this cohort have evolved according to their corresponding weight matrix"
   ],
   "id": "acc35f756b17c6c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize parameters\n",
    "N = 200  # Number of genes in a cell\n",
    "num_of_cells = 100  #100  # (M) Number of cells in each cohort = # of defects matrices\n",
    "avg_deg = 3  # Average # of non-zero elements in the matrix W\n",
    "\n",
    "decide = lambda x: np.random.random() < x\n",
    "q = 2  # Affects the range of the random numbers generated\n",
    "num_of_cohorts = 5\n",
    "p = 0.2\n",
    "step_size = 1.0 / (num_of_cohorts - 1) if num_of_cohorts > 1 else 0\n",
    "p_ratios = [i * step_size for i in range(num_of_cohorts)]\n",
    "num_of_cells_to_affect = [round(p_ratios[i] * num_of_cells) for i in range(num_of_cohorts)]\n",
    "W = [[np.zeros((N, N)) for _ in range(num_of_cells)] for ___ in range(\n",
    "    num_of_cohorts)]  # Initialize the weight matrix with zeros. W[cohort index][defect index / cell index][(row, column)] Perhaps there is a simpler more elegant way to do this with smaller dimension arrays.\n",
    "\n",
    "# I.C is an array where each element represents a cohort with different p and each cohort has an array of cells and each cell has a vector of initial conditions for each gene in the cell. initial_conditions[cohort index][defect index / cell index][gene index]\n",
    "initial_conditions = [[np.random.rand(N) for _ in range(num_of_cells)] for __ in range(num_of_cohorts)]\n",
    "\n",
    "num_of_time_stamps = 1000  # Perhaps this is unnecessary for solve_ivp (t_eval is optional)\n",
    "t_final = 20  # How will I know that 20 is enough to reach a steady state?\n",
    "t = np.linspace(0, t_final, num_of_time_stamps)"
   ],
   "id": "9dd9cc0c6767de24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(p_ratios)\n",
    "print(num_of_cells_to_affect)"
   ],
   "id": "dcaff8b7a38ab52e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for cohort_index in range(num_of_cohorts):\n",
    "    cur_num_of_cells_to_affect = num_of_cells_to_affect[cohort_index]\n",
    "    # For each cohort (group of <num_of_cells> cells), create a system of <num_of_cells> w defect matrices\n",
    "\n",
    "    # Set the base weight matrix for the current cohort\n",
    "    # TODO: this is weird since I defined avg_deg as the average degree but I use it as a probability distribution (actual average might be different) maybe change that in the future\n",
    "    # TODO: try to make the base model the same for all cohorts later\n",
    "    base_model = np.array([[np.random.uniform(0, q) if (gene_i != gene_j and decide(avg_deg / (N - 1))) else 0\n",
    "                            for gene_j in range(N)] for gene_i in range(N)])\n",
    "\n",
    "    # The first iteration is useless since p[0] = 0 by definition, and it's a simple copy of base_model. Maybe change that in the future\n",
    "    # Create defects of the weight matrix\n",
    "    # Too many indentations, maybe refactor this code\n",
    "    for defect_index in range(num_of_cells):\n",
    "        effective_p_value = p if defect_index <= cur_num_of_cells_to_affect else 0\n",
    "        for gene_i in range(N):\n",
    "            for gene_j in range(N):\n",
    "                if base_model[gene_i, gene_j] != 0:\n",
    "                    if decide(effective_p_value):\n",
    "                        W[cohort_index][defect_index][gene_i, gene_j] = np.random.uniform(0, q)\n",
    "                    else:\n",
    "                        W[cohort_index][defect_index][gene_i, gene_j] = base_model[gene_i, gene_j]\n",
    "                else:\n",
    "                    W[cohort_index][defect_index][gene_i, gene_j] = 0"
   ],
   "id": "cde2ec34435a1b84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = [[np.zeros((num_of_time_stamps, N)) for _ in range(num_of_cells)] for __ in\n",
    "           range(num_of_cohorts)]  # Initialize the results array\n",
    "# results[cohort index][defect index][(row, column)] - rows represents timestamps, columns represent gene index\n",
    "\n",
    "# Solve the ODEs for each cell in each cohort (num_of_cells X num_of_cohorts systems of ODE's (each system has N (num_of_genes) ode's)) and the corresponding initial conditions for the cells\n",
    "B = 1  #np.random.uniform(0.8, 1.2)\n",
    "for cohort_index in range(num_of_cohorts):\n",
    "    for defect_index in range(num_of_cells):\n",
    "        # Before computing the results, make 5 of the genes in each cohort in every cell 0 and stay 0. This will create \"chain reactions\" in the network when solving the ode system\n",
    "        zero_mask = []\n",
    "        num_of_zero_genes = 5\n",
    "        for _ in range(num_of_zero_genes):\n",
    "            gene_index = np.random.randint(0, N - 1)\n",
    "            initial_conditions[cohort_index][defect_index][gene_index] = 0\n",
    "            zero_mask.append(gene_index)\n",
    "        results[cohort_index][defect_index] = \\\n",
    "            solve_ivp(ode_system, [t[0], t[-1]], initial_conditions[cohort_index][defect_index],\n",
    "                      args=(W[cohort_index][defect_index], B, zero_mask), t_eval=t)[\n",
    "                \"y\"].T  # Transpose the solution so that rows = timestamps and columns = gene index"
   ],
   "id": "6485233fd53a1ff9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # Plot the results\n",
    "# for cohort_index in range(num_of_cohorts):\n",
    "#     for defect_index in range(num_of_cells):\n",
    "#         for gene in range(N):\n",
    "#             plt.plot(t, results[cohort_index][defect_index][:, gene])\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('x value')\n",
    "# plt.title('Michaelis-Menten kinetics')\n",
    "# plt.show()"
   ],
   "id": "34680243f8f87fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "steady_state = np.zeros((num_of_cohorts, N, num_of_cells))\n",
    "# steady_state[cohort index, gene index, cell index]\n",
    "\n",
    "for cohort_j in range(num_of_cohorts):\n",
    "    for cell_index in range(num_of_cells):\n",
    "        steady_state[cohort_j, :, cell_index] = results[cohort_j][cell_index][\n",
    "            -1]  # Get the last row (final time) of the cell (the steady state)"
   ],
   "id": "b31016bcdeda35f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculate Negative Spearman Correlation",
   "id": "5ae45b127d0dabe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "negative_spearman_steady_state = [(1 - (spearmanr(steady_state[i])[0])) for i in range(num_of_cohorts)]\n",
    "# spearman_steady_state[cohort index, cell_i, cell_j]"
   ],
   "id": "a73e41aa1d5806cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# get the off diagonal elements and graph a distribution of them:\n",
    "off_diagonal_elements = [[] for _ in range(num_of_cohorts)]\n",
    "# off_diagonal_elements[cohort index][off-diagonal element index]. The off-diagonal element index doesn't really have a meaning it is just a way to store these off-diagonal elements.\n",
    "\n",
    "# Store the off diagonal elements in an array of arrays (array for each cohort)\n",
    "for cohort_index in range(num_of_cohorts):\n",
    "    for cell_i in range(num_of_cells):\n",
    "        for cell_j in range(num_of_cells):\n",
    "            if cell_j > cell_i:\n",
    "                off_diagonal_elements[cohort_index].append(negative_spearman_steady_state[cohort_index][cell_i][cell_j])\n",
    "\n",
    "# Round to 2 decimal places to make the graph look normal\n",
    "off_diagonal_elements = [np.round(element, decimals=2) for element in off_diagonal_elements]"
   ],
   "id": "cac0ff0922b859fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the off-diagonal elements distribution\n",
    "for cohort_index in range(num_of_cohorts):\n",
    "    plt.hist(off_diagonal_elements[cohort_index], alpha=0.5,\n",
    "             label='cohort with {:.2f}% affected cells'.format(p_ratios[cohort_index]))\n",
    "\n",
    "plt.title('Off-diagonal negative spearman matrix elements')  # (matrix is symmetric)\n",
    "plt.xlabel('Negative Spearman value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "8881599cb994963f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "negative_spearman_steady_state[3].round()",
   "id": "9c90951e4042565"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1: Flatten the results array (cohorts, cells, genes) into a 2D array (cells x genes)\n",
    "# This way we can scale according to all the results\n",
    "flattened_data = []\n",
    "cohort_labels = []\n",
    "\n",
    "# Flatten results and create cohort labels (p = 0, ..., p = 1)\n",
    "for cohort_index in range(num_of_cohorts):\n",
    "    for cell_index in range(num_of_cells):\n",
    "        # Flatten gene data for each cell and add to flattened_data\n",
    "        flattened_data.append(results[cohort_index][cell_index].flatten())\n",
    "        cohort_labels.append(f'percentage of affected cells = {p_ratios[cohort_index]}')\n",
    "\n",
    "# Convert to a DataFrame\n",
    "flattened_data = np.array(flattened_data)\n",
    "data_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Step 2: Scale the data across *all* cells\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_df)\n",
    "\n",
    "# Step 3: Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "pc1 = 'Principal Component 1 (accounts for {:.2f}% of the variation)'.format(pca.explained_variance_ratio_[0] * 100)\n",
    "pc2 = 'Principal Component 2 (accounts for {:.2f}% of the variation)'.format(pca.explained_variance_ratio_[1] * 100)\n",
    "\n",
    "# Convert PCA result to a DataFrame and add cohort information\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=[pc1, pc2])\n",
    "pca_df['cohort'] = cohort_labels\n",
    "\n",
    "# Step 4: Plot the PCA results\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=pc1, y=pc2, hue='cohort', data=pca_df, legend='full')\n",
    "plt.title('PCA of All Cells group by Cohort')\n",
    "plt.show()"
   ],
   "id": "bbf8a97c3548211c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### PCA\n",
    "check out this video: https://youtu.be/FgakZw6K1QQ\n",
    "\n",
    "##### PC1\n",
    "- Calculate the average measurement for gene 1, 2, 3, ..., N - get the \"center\" of the data\n",
    "- Recalculate the data relative to center (the center is the origin).\n",
    "- Find the best fit linear line that passes through the origin for the data by choosing the line that maximizes the sum of the distances of the points projected by each one of the points on to the line - this line is PC1.\n",
    "- Normalize the line to unit length it is the eigen vector (also called singular vector) of PC1. the proportion of each gene are called \"loading scores\" (kind of like tan(theta) = y/x in 2d). The average of the sum of squared distances (of the points projected on to the PC1 line) is the eigen value for PC1. The square root of the sum of the squared distances is called the singular value for PC1\n",
    "\n",
    "##### PC2\n",
    "- The line that is perpendicular to PC1 (m_pc1 * m_pc2 = -1 for 2d, the number of PC's will be the MIN(variables (genes), samples(cells))) This line is the eigen vector for PC2. The loading scores are the projection of the normalized line on to the gene1 axis (x) and the projection of the normalized line on to the gene2 axis (y). The average of the sum of squared distances (of the points projected on to the PC2 line) is the eigen value for PC2.\n",
    "\n",
    "PC1 accounts for eigen_value_pc1/(eigen_value_pc1 + eigen_value_pc2) of the total variation\n",
    "PC2 accounts for eigen_value_pc2 / (eigen_value_pc1 + eigen_value_pc2) of the total variation\n",
    "\n",
    "We may have many PCi's, but after we calculated the principal components we simply project them to the 2 most dominant pc's (the ones with the highest eigen value i.e. highest variation) NOTE: this will only be good if they account for most of the variation.\n",
    "Use a scree plot for the PCi's"
   ],
   "id": "9d74c5217654825c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(len(W))  # num_of_cohorts. W is an array that each element represents a cohort with different p\n",
    "print(len(W[\n",
    "              num_of_cohorts - 1]))  # num_of_cells. An element in W is an array of 50 weight matrices (each corresponds to a cell)\n",
    "print(\n",
    "    len(W[num_of_cohorts - 1][num_of_cells - 1]))  # N (num of genes in each cell). Each weight matrix is an NxN matrix\n",
    "print(W[num_of_cohorts - 1][num_of_cells - 1][(\n",
    "    N - 1, N - 1)])  # A connection between the last gene with itself in the last cell in the last cohort (should be 0)"
   ],
   "id": "59bb159c214c4eae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate jackknife for every cohort's steady state\n",
    "jackknife_results = []\n",
    "for cohort_index in range(num_of_cohorts):\n",
    "    jackknife_results.append(jackknife(steady_state[cohort_index], 50, 0.75, 50))\n",
    "\n",
    "# Plot a violin plot of the jackknife results such that every violin represents a cohort\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.violinplot(data=jackknife_results, legend='full')\n",
    "plt.title('Jackknife results for every cohort')\n",
    "plt.show()"
   ],
   "id": "bcbcdc45ca959415"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5dab9c0831b0a15e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for f in range(num_of_cells):\n",
    "    if (all((W[0][0] == W[0][f]).flatten())):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"False\")\n"
   ],
   "id": "367f24feab11aa2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# steady_state[cohort index, gene index, cell index]\n",
    "temp = steady_state[0].round(3)\n"
   ],
   "id": "23d8c9de835e7bee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "temp",
   "id": "9d5687e07fae1611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d1cb36324632033e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
